[unix_http_server]
file = {{.app_container_path}}run/supervisord.sock

[supervisorctl]
configuration = {{.app_container_path}}conf/supervisord.conf
serverurl = unix://{{.app_container_path}}run/supervisord.sock

[supervisord]
pidfile = {{.app_container_path}}run/supervisord.pid
logfile = {{.app_container_path}}logs/{{.app_code}}/supervisord.log
directory = {{.app_container_path}}

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[program: {{.app_code}}_uwsgi]
command = /cache/.bk/env/bin/uwsgi --ini {{.app_container_path}}conf/{{.app_code}}.ini
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/uwsgi.log
redirect_stderr = true
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -n {{.node_name}}_{{.app_code}} -Q default -c 8 -l INFO --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery_pipeline_1]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -Q pipeline -n {{.node_name}}_{{.app_code}}_pipeline_1 -l INFO -c 8 --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery_pipeline_2]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -Q pipeline -n {{.node_name}}_{{.app_code}}_pipeline_2 -l INFO -c 8 --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery_service_schedule_1]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -Q service_schedule -n {{.node_name}}_{{.app_code}}_service_schedule_1 -l INFO -P gevent -c 128 --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery_service_schedule_2]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -Q service_schedule -n {{.node_name}}_{{.app_code}}_service_schedule_2 -l INFO -P gevent -c 128 --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}

[program: {{.app_code}}_celery_addtional_task]
command = /cache/.bk/env/bin/python {{.app_container_path}}code/manage.py celery worker -Q pipeline_additional_task -n {{.node_name}}_{{.app_code}}_addtional_task -l INFO -c 8 --maxtasksperchild=128
directory = {{.app_container_path}}code/
stdout_logfile = {{.app_container_path}}logs/{{.app_code}}/celery.log
redirect_stderr = true
stopwaitsecs = 10
autorestart = true
environment = {{.environment}}
